{
    "docs": [
        {
            "location": "/", 
            "text": "Welcome to the Wiki for this project.\n\n\nThe purpose of this software is to provide a convenient and reliable set of signal processing tools for developers to integrate into their project to better utilise the suite of sensors provided on an iPhone. While these sensors are powerful, the data they produce is often noisy and in need of cleaning before it can be integrated into any user-facing feature. Creating a filter to this that has the right characteristics for your application can be an extremely time consuming task, and often requires knowledge of digital signal processing to be effective. \n\n\nThis library provides an alternative to that, with ready to use filters that can be customised and integrated into your application quickly. The filters can be applied to almost any data source from iOS or elsewhere, and have been designed to maximise ease of use for someone with little or no signal processing experience. With this in mind, the key features of the filters include:\n\n\n\n\nA consistent, easy to use interface and simple data model\n\n\n\u201cDrag and drop\u201d functionality. Each filter can operate as a standalone class. No project imports or external dependencies required.\n\n\nThe latest Swift 3 syntax.\n\n\nConcurrent calculations where necessary. This document will lay out the characteristics, parameters and performance of each filter, along with usage guidance and testing information. Also available is a showcase app that demonstrates each filter in real time, compatible with iPhone and iPad. If you are looking to implement one of these filters, the code for this project can be used to assist in that process", 
            "title": "Home"
        }, 
        {
            "location": "/Library-Organisation/", 
            "text": "The library provided here consists of two main components. First, the filter algorithms, which can all be found in the Filters group of the project. Note that these filters are compatible with all iOS and Mac OS devices, including the Apple Watch and can be used in isolation from the rest of the project. Second is the supporting code that can be used to aid the use of sensor data in your application. All of these classes can be found in the \nglobalModel\n group of the project. These are classes that have been specifically designed to run on iOS and Watch OS devices, and include features such as a communication stack for streaming sensor data from an Apple Watch and a class for comprehensive sensor management. These are discussed further in the following sections.", 
            "title": "Library Organisation"
        }, 
        {
            "location": "/How-to-Use-the-Showcase-App/", 
            "text": "Introduction\n\n\nEach filter behaves differently, and is suited to different applications. To ease in the process of choosing the right filter for you, a showcase app is available that can be used to analyse and experiment with each filter to find the right configuration for your application. The app\u2019s source code is available on GitHub, and it will be downloadable on the Apple App Store. \n\n\nKey Features\n\n\nThe data displayed in the graph is the real-time output of the iPhone\u2019s accelerometer in the x-axis by default, with a series for raw and processed data. The source and axis of the data can be changed by tapping the Settings button. Here the scale can be modified and the graph can be split into two, with one for raw and processed data respectively.\nBelow is table of the available filters that can be applied to the data. Tapping on each one will reveal the configuration page for that filter. Here, the filter can be switched on and off, and the parameters modified. The changes to the filter settings are reflected on the graph in real time. Experiment with this to find a data output that works for your application. Some things to consider when choosing a filter and configuration:\n\n\n\n\nIs it more important that the amplitude or frequency of that acceleration be preserved?\n\n\nDo you want to remove noise from the data, or correct for bias caused by factors such as gravity?\n\n\nIs it more important to get fresh data or clean data? In other words, is the performance of the filter or quality of its output more \n\n\nDoes the data change slowly over time, or quickly in bursts?\n\n\n\n\nYour answers to these questions should guide your choice, along with the observed be behaviour in the showcase app and information provided in this document. Each one of the above priorities lends itself to a different filter. \nThe app allows the viewing and recording real-time data from the device\u2019s sensors, which can be exported in JSON or CSV format. The format of the JSON and CSV export files can be seen below\n\n\nJSON Format\n\n\n{\n    date: \"yyyy-MM-dd HH:mm:ss '+'ZZZZ\",\n    filters: {\n        filterName: {\n            paramName: DoubleValue\n        }\n    }\n    processed: [\n        {\n            ID:Int\n            x:Int\n            y:Int\n            z:Int\n        }\n    ],\n    raw: [\n        {\n            ID:Int\n            x:Int\n            y:Int\n            z:Int\n        }\n    ]\n}\n\n\n\nCSV Format\n\n\nID,rawX,rawY,rawZ,processedX,processedY,processedZ\n\n\n\nNote that these patterns will be reproduced for every sensor active.\n\n\nThis data can be emailed as a .txt attachment. To use this feature, tap the Record tab on the bottom of the app. \nPreviously recorded captures can be accessed by tapping the Saved Captures button at the bottom of the data capture page. Here a table of captures is displayed, ordered by date. The data in the filters section of the JSON export can be used to configure the parameters of the filter upon implementation. Note that it is possible to enable more than one filter at once, and the order in which they are applied to the data will influence the output. As such, the order of the filters in the JSON output reflects the true order.\nFor details on how to do this, see the Filter Interface section directly below.\nTo export, tap on the desired capture, which will cause an email to be composed with the selected data attached. They can be removed from storage by swiping right and tapping delete.", 
            "title": "How to Use the Showcase App"
        }, 
        {
            "location": "/How-to-Use-the-Showcase-App/#introduction", 
            "text": "Each filter behaves differently, and is suited to different applications. To ease in the process of choosing the right filter for you, a showcase app is available that can be used to analyse and experiment with each filter to find the right configuration for your application. The app\u2019s source code is available on GitHub, and it will be downloadable on the Apple App Store.", 
            "title": "Introduction"
        }, 
        {
            "location": "/How-to-Use-the-Showcase-App/#key-features", 
            "text": "The data displayed in the graph is the real-time output of the iPhone\u2019s accelerometer in the x-axis by default, with a series for raw and processed data. The source and axis of the data can be changed by tapping the Settings button. Here the scale can be modified and the graph can be split into two, with one for raw and processed data respectively.\nBelow is table of the available filters that can be applied to the data. Tapping on each one will reveal the configuration page for that filter. Here, the filter can be switched on and off, and the parameters modified. The changes to the filter settings are reflected on the graph in real time. Experiment with this to find a data output that works for your application. Some things to consider when choosing a filter and configuration:   Is it more important that the amplitude or frequency of that acceleration be preserved?  Do you want to remove noise from the data, or correct for bias caused by factors such as gravity?  Is it more important to get fresh data or clean data? In other words, is the performance of the filter or quality of its output more   Does the data change slowly over time, or quickly in bursts?   Your answers to these questions should guide your choice, along with the observed be behaviour in the showcase app and information provided in this document. Each one of the above priorities lends itself to a different filter. \nThe app allows the viewing and recording real-time data from the device\u2019s sensors, which can be exported in JSON or CSV format. The format of the JSON and CSV export files can be seen below", 
            "title": "Key Features"
        }, 
        {
            "location": "/How-to-Use-the-Showcase-App/#json-format", 
            "text": "{\n    date: \"yyyy-MM-dd HH:mm:ss '+'ZZZZ\",\n    filters: {\n        filterName: {\n            paramName: DoubleValue\n        }\n    }\n    processed: [\n        {\n            ID:Int\n            x:Int\n            y:Int\n            z:Int\n        }\n    ],\n    raw: [\n        {\n            ID:Int\n            x:Int\n            y:Int\n            z:Int\n        }\n    ]\n}", 
            "title": "JSON Format"
        }, 
        {
            "location": "/How-to-Use-the-Showcase-App/#csv-format", 
            "text": "ID,rawX,rawY,rawZ,processedX,processedY,processedZ  Note that these patterns will be reproduced for every sensor active.  This data can be emailed as a .txt attachment. To use this feature, tap the Record tab on the bottom of the app. \nPreviously recorded captures can be accessed by tapping the Saved Captures button at the bottom of the data capture page. Here a table of captures is displayed, ordered by date. The data in the filters section of the JSON export can be used to configure the parameters of the filter upon implementation. Note that it is possible to enable more than one filter at once, and the order in which they are applied to the data will influence the output. As such, the order of the filters in the JSON output reflects the true order.\nFor details on how to do this, see the Filter Interface section directly below.\nTo export, tap on the desired capture, which will cause an email to be composed with the selected data attached. They can be removed from storage by swiping right and tapping delete.", 
            "title": "CSV Format"
        }, 
        {
            "location": "/Using-An-Apple-Watch-With-the-Showcase-App/", 
            "text": "The showcase app provides the functionality to stream data from a paired apple watch, which can then the graphed, filtered and recorded like local data. \nInstall the application on the Apple Watch by navigating to the DataFil row in the apps section of the Watch app. \nTo connect and start streaming, ensure the devices are paired, connected and unlocked, then:\n\n\nOn the Watch\n\n\n\n\nOpen the DataFil app.\n\n\nPress start streaming. This will begin the publishing of data to the iPhone once connected.\n\n\n\n\n*On the iPhone\n*\n\n\n\n\nOpen the DataFil app and navigate to the watch tab. Ensure that the supported status is YES. \n\n\nTap the connect button. Installation status and Listening for data should both turn to YES. \n\n\nIn the settings of the graph, the device input can now be switched between iPhone and Watch. \n\n\nAt the top of the data recording view, the data source to collect from can now also be switched between.", 
            "title": "Using An Apple Watch With the Showcase App"
        }, 
        {
            "location": "/Using-the-Data-Source-Manager/", 
            "text": "The \ndataSourceManager\n provides a tool to manage the sensor capabilities of the device. When enabled, it will create \naccelPoint\n objects that contain all the available sensor data, numbered sequentially. It can be instantiated on either an iOS or Watch OS device, and when running will post notifications under the name \nnewRawData\n, that can be observed for globally that contain the latest \naccelPoint\n object. The \nfilterManager\n class is set up by default to observe for these notifications for data to process.\nTo change sensor sample rate, a notification of the following format can be posted from anywhere in the application, where \nsampleRate\n is the double value of the desired rate:\n\n\nNotificationCenter.default.post(\n    name: Notification.Name(\"newDatasourceSettings\"), \n    object: nil, \n    userInfo:[\"sampleRate\":sampleRate]\n)\n\n\n\nThe function to extract the \naccelPoint\n would then be as follows:\n\n\n@objc func newRawData(notification: NSNotification){\n\u00a0 \u00a0 \u00a0 \u00a0 let data = notification.userInfo as! Dictionary\n\n\u00a0 \u00a0 \u00a0 \u00a0 let accelData = data[\"data\"]\n\u00a0 \u00a0 }\n\n\nFunction Summary\n\n\nInitialiser\n\n\ninit(sourceId: String)\n\n\nThe source ID will be printed alongside any debugging statements to identify the source of the message, to ease development when working with remote devices.\n\n\nInitaliseDataSources\n\n\nfunc initaliseDatasources()\n\n\nWhen called, the \ndataSourceManager\n will attempt to startup all available sensors on the device. When ready, it will begin posting this data as \naccelPoint\n objects, in notifications under the name \nnewRawData\n. As such, this data could be observed for using the following code:\n\n\nNotificationCenter.default.addObserver(self, selector: #selector(FilterManager.newRawData), name: Notification.Name(\"newRawData\"), object: nil)\n\n\n\ndeinitDataSources\n\n\nfunc deinitDatasources()\n\n\nWhen called, the \ndataSourceManager\n will stop posting notifications with new raw data and will stop requesting sensor updates from the system. Should be used when data is no longer required to conserve power.\n\n\nmodifyDataSources\n\n\nfunc modifyDataSources(accel:Bool,gyro:Bool,mag:Bool)\n\n\nUsed to choose the active sensors. Unneeded sensors should be disabled using this method to conserve power. Placeholder 0 values will be used in the disabled sensor fields of posted \naccelPoints", 
            "title": "Using the Data Source Manager"
        }, 
        {
            "location": "/Using-the-Data-Source-Manager/#function-summary", 
            "text": "", 
            "title": "Function Summary"
        }, 
        {
            "location": "/Using-the-Data-Source-Manager/#initialiser", 
            "text": "init(sourceId: String)  The source ID will be printed alongside any debugging statements to identify the source of the message, to ease development when working with remote devices.", 
            "title": "Initialiser"
        }, 
        {
            "location": "/Using-the-Data-Source-Manager/#initalisedatasources", 
            "text": "func initaliseDatasources()  When called, the  dataSourceManager  will attempt to startup all available sensors on the device. When ready, it will begin posting this data as  accelPoint  objects, in notifications under the name  newRawData . As such, this data could be observed for using the following code:  NotificationCenter.default.addObserver(self, selector: #selector(FilterManager.newRawData), name: Notification.Name(\"newRawData\"), object: nil)", 
            "title": "InitaliseDataSources"
        }, 
        {
            "location": "/Using-the-Data-Source-Manager/#deinitdatasources", 
            "text": "func deinitDatasources()  When called, the  dataSourceManager  will stop posting notifications with new raw data and will stop requesting sensor updates from the system. Should be used when data is no longer required to conserve power.", 
            "title": "deinitDataSources"
        }, 
        {
            "location": "/Using-the-Data-Source-Manager/#modifydatasources", 
            "text": "func modifyDataSources(accel:Bool,gyro:Bool,mag:Bool)  Used to choose the active sensors. Unneeded sensors should be disabled using this method to conserve power. Placeholder 0 values will be used in the disabled sensor fields of posted  accelPoints", 
            "title": "modifyDataSources"
        }, 
        {
            "location": "/Using-the-Filter-Manager/", 
            "text": "The \nfilterManager\n class provides a convenient way to manage the flow of sensor data through your application, particularly if using more than one filter simultaneously. It allows for filters to be connected to each other, and for data to be sent from the sensor source by notification. The addition of the filter manager to your project allows raw data to be directed into and processed data out of the filters with minimal modification to your existing code. To apply a filter using \nfilterManager\n:\n\n\n\n\nfilterManager\n is a singleton, so once the singleton is initialised it can be referred to globally. \n\n\nData can be directed at the filterManager by passing it in a notification with the following format. Initialising the filterManager will cause it to observe for this notification. Using the \ndataSourceManager\n class will direct sensor data at the class automatically using this system.\n\n\nname:\u201dnewRawData\u201d\n\n\nuserInfo: [\u201cdata\u201d:accelPoint]\n\n\n\n\n\n\nTo enable a filter, simply pass the name of the filter as described in the details below to the function \naddNewFilter\n, as a string. This can be done multiple times to add as many filters as required.\n\n\nThis will cause the filter manager to post notifications with the processed data from this filter with a name \nnewProcessedData\n.\n\n\n\n\nThe workflow above describes the initial setup of the manager. The complete set of functions is described in the documentation for this class below. While \nfilterManager\n can make using the included algorithms easier, it is optional. All filters will function without it. To see an example of how the \nfilterManager\n can be linked between your data sources and sinks, see the showcase app code. \n\n\nExample Set Up\n\n\nBelow is an example set up of the filterManager. To set up three filters, in order, we would execute:\n\n\nlet filMan = filterManager.sharedInstance()\nfilMan.addNewFilter(\"High Pass\")\nfilMan.addNewFilter(\"Low Pass\")\nfilMan.addNewFilter(\"Clipping\")\n\n\n\nTo remove a filter and replace it with another, we would execute:\n\n\nfilMan.removeFilter(\"Low Pass\")\nfilMan.addNewFilter(\"Kalman\")\n\n\n\nTo the other parts of the system the data flow remains unchanged. The data source and sink are unaware of this change to the system, effectively maintaining separation between our model, controller and view layers.  \n\n\nVariable Summary\n\n\n\n\n\n\n\n\nName and Type\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nSharedInstance:FilterManager\n (static constant)\n\n\nSingleton variable for the class\n\n\n\n\n\n\nactiveFilters:[Filter]\n\n\nArray of objects that implement the \nFilter\n protocol, that raw or partially processed data will be passed to. The filter manager expects these objects to eventually return an \naccelPoint\n and is listening for this.\n\n\n\n\n\n\n\n\nFunction Summary\n\n\nnewRawData\n\n\n@objc func newRawData(notification: NSNotification)\n\n\nFunction nominated by the selector of the observer for new raw data from any source. Expects data to be passed in \nuserData\n as:\n    notification.userInfo as! Dictionary\n\nThis function will only ever be called in response to a notification from an observed data source. To enable this, it must be exposed to objective-C, through the \n@objc\n annotation. When called, the function will pass the data into the chain of filters. \nIf no filters are present, it will pass the raw data directly to the output.\n\n\nremoveFilter\n\n\nfunc removeFilter(filterName: String)\n\n\nFunction will deactivate the filter with the given name, if active. This will cause the data flow to bypass this filter, and either go to the next in the chain or the output.\n\n\nsetFilterPeramater\n\n\nfunc setFilterParameter(filterName: String, parameterName: String, parameterValue: Double)\n\n\nIf active, this function will find the named filter and set the named parameter to the described value. This can be executed at any time. All filters will accept new parameters and update accordingly at any point. A filter may complain if an invalid parameter is passed in, however it is important to check the values being passed in fall within acceptable range. For more information check the specification of the filter in question.\n\n\nreceiveData\n\n\nfunc receiveData(data: [accelPoint], id:Int)\n\n\nThis function is called by active filters when they have new data to pass on. This can happen at any point. If there is processed data available to be passed to the data sink, a notification with the name \nnewProcessedData\n will be made, with the new data points in the \nuserData\n of the notification. This will have the format:\n    \nnotification.userInfo as! Dictionary\nString,accelPoint\n\nNote that the amount of new points can be any non-zero value, and that every call to receive data may not result in a notification for new data. To collect processed data, your application should observe these notifications.", 
            "title": "Using the Filter Manager"
        }, 
        {
            "location": "/Using-the-Filter-Manager/#example-set-up", 
            "text": "Below is an example set up of the filterManager. To set up three filters, in order, we would execute:  let filMan = filterManager.sharedInstance()\nfilMan.addNewFilter(\"High Pass\")\nfilMan.addNewFilter(\"Low Pass\")\nfilMan.addNewFilter(\"Clipping\")  To remove a filter and replace it with another, we would execute:  filMan.removeFilter(\"Low Pass\")\nfilMan.addNewFilter(\"Kalman\")  To the other parts of the system the data flow remains unchanged. The data source and sink are unaware of this change to the system, effectively maintaining separation between our model, controller and view layers.", 
            "title": "Example Set Up"
        }, 
        {
            "location": "/Using-the-Filter-Manager/#variable-summary", 
            "text": "Name and Type  Description      SharedInstance:FilterManager  (static constant)  Singleton variable for the class    activeFilters:[Filter]  Array of objects that implement the  Filter  protocol, that raw or partially processed data will be passed to. The filter manager expects these objects to eventually return an  accelPoint  and is listening for this.", 
            "title": "Variable Summary"
        }, 
        {
            "location": "/Using-the-Filter-Manager/#function-summary", 
            "text": "", 
            "title": "Function Summary"
        }, 
        {
            "location": "/Using-the-Filter-Manager/#newrawdata", 
            "text": "@objc func newRawData(notification: NSNotification)  Function nominated by the selector of the observer for new raw data from any source. Expects data to be passed in  userData  as:\n    notification.userInfo as! Dictionary \nThis function will only ever be called in response to a notification from an observed data source. To enable this, it must be exposed to objective-C, through the  @objc  annotation. When called, the function will pass the data into the chain of filters. \nIf no filters are present, it will pass the raw data directly to the output.", 
            "title": "newRawData"
        }, 
        {
            "location": "/Using-the-Filter-Manager/#removefilter", 
            "text": "func removeFilter(filterName: String)  Function will deactivate the filter with the given name, if active. This will cause the data flow to bypass this filter, and either go to the next in the chain or the output.", 
            "title": "removeFilter"
        }, 
        {
            "location": "/Using-the-Filter-Manager/#setfilterperamater", 
            "text": "func setFilterParameter(filterName: String, parameterName: String, parameterValue: Double)  If active, this function will find the named filter and set the named parameter to the described value. This can be executed at any time. All filters will accept new parameters and update accordingly at any point. A filter may complain if an invalid parameter is passed in, however it is important to check the values being passed in fall within acceptable range. For more information check the specification of the filter in question.", 
            "title": "setFilterPeramater"
        }, 
        {
            "location": "/Using-the-Filter-Manager/#receivedata", 
            "text": "func receiveData(data: [accelPoint], id:Int)  This function is called by active filters when they have new data to pass on. This can happen at any point. If there is processed data available to be passed to the data sink, a notification with the name  newProcessedData  will be made, with the new data points in the  userData  of the notification. This will have the format:\n     notification.userInfo as! Dictionary String,accelPoint \nNote that the amount of new points can be any non-zero value, and that every call to receive data may not result in a notification for new data. To collect processed data, your application should observe these notifications.", 
            "title": "receiveData"
        }, 
        {
            "location": "/Implementing-Apple-Watch-Sensor-Communication/", 
            "text": "The communication of data to and from the Apple Watch is handled using the following classes, found in the globalModel group:\n\n\n\n\nRemoteDataInterface\n\n\nSerialiser\n\n\nRemoteCommunicator\n\n\n\n\nThe stack is symmetrical, meaning that the same code can be used to start a session from both devices. In the following sections, each class in the stack is described. \n\n\nRemote Communicator\n\n\nThe \nRemoteCommunicator\n class is the lowest level in this process, used to manage the communication session with the remote device, and is independent of any other part of the application, meaning it can be used to send any arbitrary message to and from the watch. Messages are sent as a key value pair, and observers can subscribe to be notified when a message with a matching key arrives. This allows messages of different types to be sent and received to specific parts of the application without the need to determine if a specific message is relevant in the main logic of the application. Each observing communicator can assume that if it is notified of a message that it was intended for them. \n\n\nThe class is instantiated with a \ndeviceId\n, for debugging purposes, allowing the source devices of console messages to be traced. It also contains several methods for checking if the remote partner is connected and reachable. \n\n\nFunction Summary\n\n\nStart\n\n\nfunc start(deviceId: String)\n\n\nAttempts to start a session with the remote device. Should this not be possible an error message will be printed to the console. This method must be called before attempting communication.\n\n\nisSupported\n\n\nfunc isSupported() -\n Bool\n\n\nReturns a Boolean detailing if Apple Watch communication is supported by the device.\n\n\nwatchIsConnected\n\n\nfunc watchIsConnected() -\n Bool\n\n\nReturns a Boolean detailing if an Apple Watch is connected and can be reached for communication.\n\n\nsendMessage\n\n\nfunc sendMessage(key: String, value: Any)\n\n\nAttempts to send a message with key and value passed into the function to the remote device. If this fails, a message will be printed to the console. On the remote device, any observer subscribed to messages with the matching key will be notified of the contents.\n\n\naddObserver\n\n\nfunc addObserver(key: String, update: @escaping (Any) -\n Void)\n\n\nAdds a callback from an observing class that will be called when a message with a matching key arrives from the remote device. It must accept any object as this is what can be passed into the \nsendMessage\n function on the remote partner.\n\n\nRemote Data Interface\n\n\nNext in the stack is the logic specific to sending and receiving sensor data. This is the responsibility of the \nremoteDataInterface\n. It can be used to send outgoing sensor data to the remote partner, by observing for new local data though the same observer system used for all consumers. The \nremoteDataInterface\n can observe to the \nremoteCommunicator\n class to listen for new incoming remote data, which will arrive under a specific key. When listening, it will notify other consumers of sensor data using the same notification format as local sensor data notifications, meaning that any consumer of local data can be trivially switched to listen for remote data. This symmetry of the communication hierarchy and uniform processing of remote and local data means that if desired, the watch could listen for sensor data from the iPhone, or even another watch. There is no pre-defined rigid data flow. \n\n\nNote that remoteDataInterface is a singleton.\n\n\nFunction Summary\n\n\npublishOutgoingData\n\n\nfunc publishOutgoingData()\n\n\nWhen called the class will begin attempting to send new raw data published by the \ndataSourceManager\n to the remote device. Can be used to send raw data from the Apple Watch to the iPhone.\n\n\nsubscribeIncomingData\n\n\nfunc subscribeIncomingData()\n\n\nWill cause the device to start listening to messages sent from the \npublishOutgoingData\n function on the remote device. When received, the data will be published globally under a notification named \nnewRemoteData\n. \n\n\nSerialiser\n\n\nIt is important to note that it is not possible simply to send \naccelPoint\n objects to a remote device. The communication protocol defined by Apple can only accept primitive objects such as Strings, Doubles and Integers. For this reason, the \nremoteDataInterface\n will serialise each \naccelPoint\n, using the \nSerialiser\n class before sending. When receiving, it will de-serialise the incoming primitive back into an \naccelPoint\n object before notifying consumers of this data. This process is transparent to the sender and receiver of the sensor data, and part of the hierarchical design of the communication. These functions do not need to be called directly, they are used as required by the \nremoteDataInterface\n for sending and receiving.\n\n\nFunction Summary\n\n\nserialise\n\n\nserialise(input: accelPoint) -\n String\n\n\nWill convert a valid \naccelPoint\n object into a \nString\n for sending. Reversed with \ndeserialise\n.\n\n\ndeserialise\n\n\ndeserialise(input: String) -\n accelPoint\n\n\nWill convert a valid \nString\n into an \naccelPoint\n object. Reverse of \nserialise\n function.", 
            "title": "Implementing Apple Watch Sensor Communication"
        }, 
        {
            "location": "/Implementing-Apple-Watch-Sensor-Communication/#remote-communicator", 
            "text": "The  RemoteCommunicator  class is the lowest level in this process, used to manage the communication session with the remote device, and is independent of any other part of the application, meaning it can be used to send any arbitrary message to and from the watch. Messages are sent as a key value pair, and observers can subscribe to be notified when a message with a matching key arrives. This allows messages of different types to be sent and received to specific parts of the application without the need to determine if a specific message is relevant in the main logic of the application. Each observing communicator can assume that if it is notified of a message that it was intended for them.   The class is instantiated with a  deviceId , for debugging purposes, allowing the source devices of console messages to be traced. It also contains several methods for checking if the remote partner is connected and reachable.", 
            "title": "Remote Communicator"
        }, 
        {
            "location": "/Implementing-Apple-Watch-Sensor-Communication/#function-summary", 
            "text": "", 
            "title": "Function Summary"
        }, 
        {
            "location": "/Implementing-Apple-Watch-Sensor-Communication/#start", 
            "text": "func start(deviceId: String)  Attempts to start a session with the remote device. Should this not be possible an error message will be printed to the console. This method must be called before attempting communication.", 
            "title": "Start"
        }, 
        {
            "location": "/Implementing-Apple-Watch-Sensor-Communication/#issupported", 
            "text": "func isSupported() -  Bool  Returns a Boolean detailing if Apple Watch communication is supported by the device.", 
            "title": "isSupported"
        }, 
        {
            "location": "/Implementing-Apple-Watch-Sensor-Communication/#watchisconnected", 
            "text": "func watchIsConnected() -  Bool  Returns a Boolean detailing if an Apple Watch is connected and can be reached for communication.", 
            "title": "watchIsConnected"
        }, 
        {
            "location": "/Implementing-Apple-Watch-Sensor-Communication/#sendmessage", 
            "text": "func sendMessage(key: String, value: Any)  Attempts to send a message with key and value passed into the function to the remote device. If this fails, a message will be printed to the console. On the remote device, any observer subscribed to messages with the matching key will be notified of the contents.", 
            "title": "sendMessage"
        }, 
        {
            "location": "/Implementing-Apple-Watch-Sensor-Communication/#addobserver", 
            "text": "func addObserver(key: String, update: @escaping (Any) -  Void)  Adds a callback from an observing class that will be called when a message with a matching key arrives from the remote device. It must accept any object as this is what can be passed into the  sendMessage  function on the remote partner.", 
            "title": "addObserver"
        }, 
        {
            "location": "/Implementing-Apple-Watch-Sensor-Communication/#remote-data-interface", 
            "text": "Next in the stack is the logic specific to sending and receiving sensor data. This is the responsibility of the  remoteDataInterface . It can be used to send outgoing sensor data to the remote partner, by observing for new local data though the same observer system used for all consumers. The  remoteDataInterface  can observe to the  remoteCommunicator  class to listen for new incoming remote data, which will arrive under a specific key. When listening, it will notify other consumers of sensor data using the same notification format as local sensor data notifications, meaning that any consumer of local data can be trivially switched to listen for remote data. This symmetry of the communication hierarchy and uniform processing of remote and local data means that if desired, the watch could listen for sensor data from the iPhone, or even another watch. There is no pre-defined rigid data flow.   Note that remoteDataInterface is a singleton.", 
            "title": "Remote Data Interface"
        }, 
        {
            "location": "/Implementing-Apple-Watch-Sensor-Communication/#function-summary_1", 
            "text": "", 
            "title": "Function Summary"
        }, 
        {
            "location": "/Implementing-Apple-Watch-Sensor-Communication/#publishoutgoingdata", 
            "text": "func publishOutgoingData()  When called the class will begin attempting to send new raw data published by the  dataSourceManager  to the remote device. Can be used to send raw data from the Apple Watch to the iPhone.", 
            "title": "publishOutgoingData"
        }, 
        {
            "location": "/Implementing-Apple-Watch-Sensor-Communication/#subscribeincomingdata", 
            "text": "func subscribeIncomingData()  Will cause the device to start listening to messages sent from the  publishOutgoingData  function on the remote device. When received, the data will be published globally under a notification named  newRemoteData .", 
            "title": "subscribeIncomingData"
        }, 
        {
            "location": "/Implementing-Apple-Watch-Sensor-Communication/#serialiser", 
            "text": "It is important to note that it is not possible simply to send  accelPoint  objects to a remote device. The communication protocol defined by Apple can only accept primitive objects such as Strings, Doubles and Integers. For this reason, the  remoteDataInterface  will serialise each  accelPoint , using the  Serialiser  class before sending. When receiving, it will de-serialise the incoming primitive back into an  accelPoint  object before notifying consumers of this data. This process is transparent to the sender and receiver of the sensor data, and part of the hierarchical design of the communication. These functions do not need to be called directly, they are used as required by the  remoteDataInterface  for sending and receiving.", 
            "title": "Serialiser"
        }, 
        {
            "location": "/Implementing-Apple-Watch-Sensor-Communication/#function-summary_2", 
            "text": "", 
            "title": "Function Summary"
        }, 
        {
            "location": "/Implementing-Apple-Watch-Sensor-Communication/#serialise", 
            "text": "serialise(input: accelPoint) -  String  Will convert a valid  accelPoint  object into a  String  for sending. Reversed with  deserialise .", 
            "title": "serialise"
        }, 
        {
            "location": "/Implementing-Apple-Watch-Sensor-Communication/#deserialise", 
            "text": "deserialise(input: String) -  accelPoint  Will convert a valid  String  into an  accelPoint  object. Reverse of  serialise  function.", 
            "title": "deserialise"
        }, 
        {
            "location": "/accelPoint-Data-Object/", 
            "text": "An \naccelPoint\n object represents an instantaneous sensor reading, with X Y and Z values. Distinct points should be given unique IDs. This ID may be for example a sequence number or a timestamp of the reading. Initialisation using the default initialiser will set all values, including ID to 0. accelPoints are used as the data model input and output for the filter algorithms, and is designed to be similar in function to Apple\u2019s implementation.\n\n\nVariable Summary\n\n\n\n\n\n\n\n\nName and Type\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nxAccel:Double\n\n\nAcceleration in the x axis in ms2\n\n\n\n\n\n\nyAccel:Double\n\n\nAcceleration in the y axis in ms2\n\n\n\n\n\n\nzAccel:Double\n\n\nAcceleration in the z axis in ms2\n\n\n\n\n\n\nxGyro:Double\n\n\nRotational velocity in x axis in rad/sec\n\n\n\n\n\n\nyGyro:Double\n\n\nRotational velocity in y axis in rad/sec\n\n\n\n\n\n\nzGyro:Double\n\n\nRotational velocity in z axis in rad/sec\n\n\n\n\n\n\nxMag:Double\n\n\nMagnetic field in x axis in militeslas\n\n\n\n\n\n\nyMag:Double\n\n\nMagnetic field in y axis in militeslas\n\n\n\n\n\n\nzMagDouble\n\n\nMagnetic field in z axis in militeslas\n\n\n\n\n\n\nCount:Int\n\n\nThe identification number of the acceleration point\n\n\n\n\n\n\n\n\nFunction Summary\n\n\nget$Axis\n\n\nfunc getAccelAxis(axis: String) -\n Double\n\n\nfunc getGyroAxis(axis: String) -\n Double\n\n\nfunc getMagAxis(axis: String) -\n Double\n\n\nUtility function used to allow data access to be configured by a string, in a similar fashion to the parameter stinging functionality provided in accelPoint. Allows for runtime changes to the axis of data that is being filtered or accessed.", 
            "title": "accelPoint Data Object"
        }, 
        {
            "location": "/accelPoint-Data-Object/#variable-summary", 
            "text": "Name and Type  Description      xAccel:Double  Acceleration in the x axis in ms2    yAccel:Double  Acceleration in the y axis in ms2    zAccel:Double  Acceleration in the z axis in ms2    xGyro:Double  Rotational velocity in x axis in rad/sec    yGyro:Double  Rotational velocity in y axis in rad/sec    zGyro:Double  Rotational velocity in z axis in rad/sec    xMag:Double  Magnetic field in x axis in militeslas    yMag:Double  Magnetic field in y axis in militeslas    zMagDouble  Magnetic field in z axis in militeslas    Count:Int  The identification number of the acceleration point", 
            "title": "Variable Summary"
        }, 
        {
            "location": "/accelPoint-Data-Object/#function-summary", 
            "text": "", 
            "title": "Function Summary"
        }, 
        {
            "location": "/accelPoint-Data-Object/#getaxis", 
            "text": "func getAccelAxis(axis: String) -  Double  func getGyroAxis(axis: String) -  Double  func getMagAxis(axis: String) -  Double  Utility function used to allow data access to be configured by a string, in a similar fashion to the parameter stinging functionality provided in accelPoint. Allows for runtime changes to the axis of data that is being filtered or accessed.", 
            "title": "get$Axis"
        }, 
        {
            "location": "/Filter-Implementation/", 
            "text": "Introduction\n\n\nThis section describes in detail how to interact with the filters in your application. Every filter included has the same interface, as defined by the FilterProtocol. The filters should only be interacted with through this interface, as while they may have other methods publicly visible for testing purposes, these methods will not configure the filter state correctly, and may lead to poor data or crashes. \n\n\nSetup and Use\n\n\nEvery filter depends on 2 classes, which should be included in your project: \n\n \naccelPoint\n\n\n \nFilter protocol\n\n\nSome filters may have additional dependencies that must be imported alongside the file. These will be specified in the section of the documentation pertaining to that filter and the class itself. \nOnce the required files have been imported into your project, the filter will be ready for use. The following workflow will then apply:\n1. Create a new filter object, using the default initialiser. As each filter will have an internal state, it is important that a filter is only used for one data stream at a time. New objects should be created to filter data from multiple sources at once. \n1. Add a callback to the filter, using the \naddSubscriberCallback\n function.\n1. Create an \naccelPoint\n object with the data to be filtered, and pass it into the filter object using the \naddDataPoint\n function\n1. Registered observer callbacks will be called with new data when it is ready.", 
            "title": "Filter Implementation"
        }, 
        {
            "location": "/Filter-Implementation/#introduction", 
            "text": "This section describes in detail how to interact with the filters in your application. Every filter included has the same interface, as defined by the FilterProtocol. The filters should only be interacted with through this interface, as while they may have other methods publicly visible for testing purposes, these methods will not configure the filter state correctly, and may lead to poor data or crashes.", 
            "title": "Introduction"
        }, 
        {
            "location": "/Filter-Implementation/#setup-and-use", 
            "text": "Every filter depends on 2 classes, which should be included in your project:    accelPoint    Filter protocol  Some filters may have additional dependencies that must be imported alongside the file. These will be specified in the section of the documentation pertaining to that filter and the class itself. \nOnce the required files have been imported into your project, the filter will be ready for use. The following workflow will then apply:\n1. Create a new filter object, using the default initialiser. As each filter will have an internal state, it is important that a filter is only used for one data stream at a time. New objects should be created to filter data from multiple sources at once. \n1. Add a callback to the filter, using the  addSubscriberCallback  function.\n1. Create an  accelPoint  object with the data to be filtered, and pass it into the filter object using the  addDataPoint  function\n1. Registered observer callbacks will be called with new data when it is ready.", 
            "title": "Setup and Use"
        }, 
        {
            "location": "/Filter-Protocol/", 
            "text": "Every filter implements this protocol, and as such it should be included in any project utilising them. It defines a standard interface that each filter will conform to. Below is a list of function definitions and their description.\n\n\nVariable Summary\n\n\n\n\n\n\n\n\nName and Type\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nfilterName:String\n\n\nGet only. The full English name of the filter\n\n\n\n\n\n\nParams: [String:Double]\n\n\nGet only. A dictionary with parameter name and values as key value pairs.\n\n\n\n\n\n\nObservers:[(_:[accelPoint])-\nVoid]\n\n\nGet only. A list of callbacks that should be executed when new data is available.\n\n\n\n\n\n\n\n\nFunction Summary\n\n\naddDataPoint\n\n\nfunc addDataPoint(dataPoint:accelPoint) -\n Void\n\n\nVoid function used to add a data point to the filter to be processed. Filter expects a unique ID, and all values to be set. \n\n\naddObserver\n\n\nfunc addSubscriberCallback(update: @escaping (_: [accelPoint])-\n Void)\n\n\nVoid function used to add a callback closure to the filter as an observer. The added observer will be executed when new processed data is available. This call will always be made on the main thread, but may be made at any time after adding a data point. It may contain any number of \naccelPoint\ns as an array, that contain the same ID as their raw counterpart but the processed values for x, y, z. The returned \naccelPoint\n object will not be same as the last one passed in, and may have a different ID, as some filters buffer values. \nThe closure has the \n@escaping\n attribute as it will be executed after the \naddSubscriberCallback\n function has returned. It must accept an argument named \ndata:[accelPoint]\n and return \nvoid\n.\n\n\nnotifySubscribers\n\n\nfunc notifySubscribers(data: [accelPoint])\n\n\nFunction called by the algorithm in the filter class to signal that new data is ready. The function should be implemented to execute all closures stored in the observers property of the filter. \nIt will pass through a non-empty array of \naccelPoint\n objects into the closures. Each \naccelPoint\n will contain the filtered data with the matching ID of the raw data counterpart.\n\n\nsetParameter\n\n\nfunc setParameter(parameterName:String, parameterValue:Double) -\n Void\n\n\nUsed to modify the parameters of the filtering algorithm. This can be done at any time during the filter\u2019s lifetime to override the default values. A list of the parameters each filter contains can be found their section of this document.", 
            "title": "Filter Protocol"
        }, 
        {
            "location": "/Filter-Protocol/#variable-summary", 
            "text": "Name and Type  Description      filterName:String  Get only. The full English name of the filter    Params: [String:Double]  Get only. A dictionary with parameter name and values as key value pairs.    Observers:[(_:[accelPoint])- Void]  Get only. A list of callbacks that should be executed when new data is available.", 
            "title": "Variable Summary"
        }, 
        {
            "location": "/Filter-Protocol/#function-summary", 
            "text": "", 
            "title": "Function Summary"
        }, 
        {
            "location": "/Filter-Protocol/#adddatapoint", 
            "text": "func addDataPoint(dataPoint:accelPoint) -  Void  Void function used to add a data point to the filter to be processed. Filter expects a unique ID, and all values to be set.", 
            "title": "addDataPoint"
        }, 
        {
            "location": "/Filter-Protocol/#addobserver", 
            "text": "func addSubscriberCallback(update: @escaping (_: [accelPoint])-  Void)  Void function used to add a callback closure to the filter as an observer. The added observer will be executed when new processed data is available. This call will always be made on the main thread, but may be made at any time after adding a data point. It may contain any number of  accelPoint s as an array, that contain the same ID as their raw counterpart but the processed values for x, y, z. The returned  accelPoint  object will not be same as the last one passed in, and may have a different ID, as some filters buffer values. \nThe closure has the  @escaping  attribute as it will be executed after the  addSubscriberCallback  function has returned. It must accept an argument named  data:[accelPoint]  and return  void .", 
            "title": "addObserver"
        }, 
        {
            "location": "/Filter-Protocol/#notifysubscribers", 
            "text": "func notifySubscribers(data: [accelPoint])  Function called by the algorithm in the filter class to signal that new data is ready. The function should be implemented to execute all closures stored in the observers property of the filter. \nIt will pass through a non-empty array of  accelPoint  objects into the closures. Each  accelPoint  will contain the filtered data with the matching ID of the raw data counterpart.", 
            "title": "notifySubscribers"
        }, 
        {
            "location": "/Filter-Protocol/#setparameter", 
            "text": "func setParameter(parameterName:String, parameterValue:Double) -  Void  Used to modify the parameters of the filtering algorithm. This can be done at any time during the filter\u2019s lifetime to override the default values. A list of the parameters each filter contains can be found their section of this document.", 
            "title": "setParameter"
        }, 
        {
            "location": "/Bounded-Average-Filter/", 
            "text": "Introduction, Usage and Behaviour\n\n\nThis filter functions by taking a moving average of a previous values and determining if it falls within a set of parameterised bounds. If it does, it outputs a value in the middle of those bounds. If it does not, the new middle value is set to the raw data value, and the bounds recreated. This results in a filter that outputs a steady signal until a threshold is met, at which point the output jumps instantaneously until the in-bounds property is recovered. \nThis filter would be well suited to situations where:\n\n\n\n\nThe signal to noise ratio is fixed. The bounds of the filter can be set just larger than the noise level, resulting in a very clean, steady signal.\n\n\nThe input data is a binary signal combined with some amount of noise. This filter is effective at recovering the original binary signal.\n\n\nLike the binary data, the output signal will fall into categories. For example magnetometer data to the directions on a compass rose. The output will be a steady signal in one of the points, and will quickly and precisely jump to the next point when the signal dictates. \n\n\n\n\nComplexity:\n\n\n\n\nFilter application: O(n) where \nn\n = number of points to consider in average. \n\n\n\n\nMemory load: \n\n\n\n\nFilter application: O(n) where \nn\n = number of points to consider in average.\nWhile the algorithm does not run in constant time, the number of historical points to consider is likely small. The algorithm can run with 0 previous values considered.  \n\n\n\n\nParameters\n\n\n\n\n\n\n\n\nName and Type\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nupperBound:Double\n  Range: 0...8\n\n\nThe upper bound beyond which the signal centre is reset and the bounds shift upwards.\n\n\n\n\n\n\nlowerBound:Double\n  Range: 0...8\n\n\nThe lower bound beyond which the signal centre is reset and the bounds shift downwards.\n\n\n\n\n\n\npointsAverage:Double\n  Range: 0...n\n\n\nThe number of points to consider in the moving average. Determines complexity.\n\n\n\n\n\n\n\n\n\n\nThe figures above show that the bounds size must be carefully matched to the expected accelerations in the application. If there are too small, the data is noisy and has many artefacts. If the bounds are too large, changes in the data are lost, and the bounds can settle at an inaccurate value.\n\n\nTesting\n\n\nTests for this filter can be found in the \nboundedAverageTests.swift\n file.", 
            "title": "Bounded Average Filter"
        }, 
        {
            "location": "/Bounded-Average-Filter/#introduction-usage-and-behaviour", 
            "text": "This filter functions by taking a moving average of a previous values and determining if it falls within a set of parameterised bounds. If it does, it outputs a value in the middle of those bounds. If it does not, the new middle value is set to the raw data value, and the bounds recreated. This results in a filter that outputs a steady signal until a threshold is met, at which point the output jumps instantaneously until the in-bounds property is recovered. \nThis filter would be well suited to situations where:   The signal to noise ratio is fixed. The bounds of the filter can be set just larger than the noise level, resulting in a very clean, steady signal.  The input data is a binary signal combined with some amount of noise. This filter is effective at recovering the original binary signal.  Like the binary data, the output signal will fall into categories. For example magnetometer data to the directions on a compass rose. The output will be a steady signal in one of the points, and will quickly and precisely jump to the next point when the signal dictates.    Complexity:   Filter application: O(n) where  n  = number of points to consider in average.    Memory load:    Filter application: O(n) where  n  = number of points to consider in average.\nWhile the algorithm does not run in constant time, the number of historical points to consider is likely small. The algorithm can run with 0 previous values considered.", 
            "title": "Introduction, Usage and Behaviour"
        }, 
        {
            "location": "/Bounded-Average-Filter/#parameters", 
            "text": "Name and Type  Description      upperBound:Double   Range: 0...8  The upper bound beyond which the signal centre is reset and the bounds shift upwards.    lowerBound:Double   Range: 0...8  The lower bound beyond which the signal centre is reset and the bounds shift downwards.    pointsAverage:Double   Range: 0...n  The number of points to consider in the moving average. Determines complexity.      The figures above show that the bounds size must be carefully matched to the expected accelerations in the application. If there are too small, the data is noisy and has many artefacts. If the bounds are too large, changes in the data are lost, and the bounds can settle at an inaccurate value.", 
            "title": "Parameters"
        }, 
        {
            "location": "/Bounded-Average-Filter/#testing", 
            "text": "Tests for this filter can be found in the  boundedAverageTests.swift  file.", 
            "title": "Testing"
        }, 
        {
            "location": "/Savitzky-Golay-Filter/", 
            "text": "Introduction, Usage and Behaviour\n\n\nThis filter is different from the previous three, in that it is non-casual. This means that it must consider both future and previous points when calculating the smoothing of the current point. This has advantages and drawbacks, the most obvious of which is that it introduces a delay proportional to the number of future points being considered.  The main advantage however is a more nuanced smoothing function that helps to maintain the amplitude and frequency of the input data, but is very effective at increasing the signal-to-noise ratio. \nThe filter functions through the use of convolution. Using linear algebra to apply a curve fitting of a second or forth degree polynomial to the data. The coefficients are calculated beforehand, by creating an imaginary curve with length n+1, where n is the number of the points to the left and right being considered. In this imaginary list, all points are set to zero apart from the centre, which is set to 1. The values of the polynomial curve that are created about this point become the coefficients that are applied to the raw data values at runtime.\n\n\n\nThe calculated coefficients are applied through the use a of a simple weighted moving average to the left and right of the point in consideration. This makes the filter computationally light at runtime.\n\n\nComplexity:\n\n\n\n\nCoefficient Calculation: O((nl+nr)^m)  where \nnl\n = leftScan and \nnr\n = rightScan and \nm\n = polynomial order (2 or 4)\n\n\nFilter application per point: O(nl+nr) where \nnl\n = leftScan and \nnr\n = rightScan\n\n\n\n\nMemory load: \n\n\n\n\nCoefficient Calculation: O((nl+nr)^m)  where \nnl\n = leftScan and \nnr\n = rightScan and \nm\n = polynomial order (2 or 4)\n\n\nFilter application per point: O(nl+nr) where \nnl\n = leftScan and \nnr\n = rightScan\n\n\n\n\nParameters\n\n\n\n\n\n\n\n\nName and Type\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nleftScan:Double\n  Range: 1...n\n\n\nDefines the number of future,points that should be considered when calculating the current point. The larger this value, the larger the delay. A large difference between the left and right range can lead to anomalous behaviour. A forward scan value slightly larger than a backward scan value can reduce under and overshoot on sudden changes.\n\n\n\n\n\n\nrightScan:Double\n   Range: 1...n\n\n\nDefines the number of historic points to be considered when calculating the current point. Does not affect delay. Does increase memory use. A higher value results in a smoother output.\n\n\n\n\n\n\nfilterPolynomial:Double\n  (rightScan+leftScan+1)...n\n\n\nThe order of the polynomial used to calculate the coefficients. A higher order polynomial filter will respond better to high amplitude changes. Note that this value must be larger than (nr+nl+1) or no filtering will be applied. An error will be displayed in the console.\n\n\n\n\n\n\n\n\n\n\nThe above graphs are examples of a good and two bad configurations of this filter. The first above shows well how a properly calibrated filter will preserve the height and width of major movements in the data. The second displays anomalous changes on the descending and ascending leg of the major movement due to a low order being used with comparatively high numbers of points being considered. Lastly, the third shows a configuration where the polynomial is too low, and the number of points considered too high for the frequency of change present in the data. The height and width of the data is lost. \n\n\nTesting\n\n\nTests for this filter can be found in the \nsavGolTests.swift\n file", 
            "title": "Savitzky Golay Filter"
        }, 
        {
            "location": "/Savitzky-Golay-Filter/#introduction-usage-and-behaviour", 
            "text": "This filter is different from the previous three, in that it is non-casual. This means that it must consider both future and previous points when calculating the smoothing of the current point. This has advantages and drawbacks, the most obvious of which is that it introduces a delay proportional to the number of future points being considered.  The main advantage however is a more nuanced smoothing function that helps to maintain the amplitude and frequency of the input data, but is very effective at increasing the signal-to-noise ratio. \nThe filter functions through the use of convolution. Using linear algebra to apply a curve fitting of a second or forth degree polynomial to the data. The coefficients are calculated beforehand, by creating an imaginary curve with length n+1, where n is the number of the points to the left and right being considered. In this imaginary list, all points are set to zero apart from the centre, which is set to 1. The values of the polynomial curve that are created about this point become the coefficients that are applied to the raw data values at runtime.  The calculated coefficients are applied through the use a of a simple weighted moving average to the left and right of the point in consideration. This makes the filter computationally light at runtime.  Complexity:   Coefficient Calculation: O((nl+nr)^m)  where  nl  = leftScan and  nr  = rightScan and  m  = polynomial order (2 or 4)  Filter application per point: O(nl+nr) where  nl  = leftScan and  nr  = rightScan   Memory load:    Coefficient Calculation: O((nl+nr)^m)  where  nl  = leftScan and  nr  = rightScan and  m  = polynomial order (2 or 4)  Filter application per point: O(nl+nr) where  nl  = leftScan and  nr  = rightScan", 
            "title": "Introduction, Usage and Behaviour"
        }, 
        {
            "location": "/Savitzky-Golay-Filter/#parameters", 
            "text": "Name and Type  Description      leftScan:Double   Range: 1...n  Defines the number of future,points that should be considered when calculating the current point. The larger this value, the larger the delay. A large difference between the left and right range can lead to anomalous behaviour. A forward scan value slightly larger than a backward scan value can reduce under and overshoot on sudden changes.    rightScan:Double    Range: 1...n  Defines the number of historic points to be considered when calculating the current point. Does not affect delay. Does increase memory use. A higher value results in a smoother output.    filterPolynomial:Double   (rightScan+leftScan+1)...n  The order of the polynomial used to calculate the coefficients. A higher order polynomial filter will respond better to high amplitude changes. Note that this value must be larger than (nr+nl+1) or no filtering will be applied. An error will be displayed in the console.      The above graphs are examples of a good and two bad configurations of this filter. The first above shows well how a properly calibrated filter will preserve the height and width of major movements in the data. The second displays anomalous changes on the descending and ascending leg of the major movement due to a low order being used with comparatively high numbers of points being considered. Lastly, the third shows a configuration where the polynomial is too low, and the number of points considered too high for the frequency of change present in the data. The height and width of the data is lost.", 
            "title": "Parameters"
        }, 
        {
            "location": "/Savitzky-Golay-Filter/#testing", 
            "text": "Tests for this filter can be found in the  savGolTests.swift  file", 
            "title": "Testing"
        }, 
        {
            "location": "/Low-Pass-Filter/", 
            "text": "Introduction, Usage and Behaviour\n\n\nThis filter is conceptually the opposite of the high pass filter. It allows low frequency signals to pass through, while removing and smoothing out the high frequency ones. This makes it useful for removing noise from a signal. This filter is generic, and uses a coefficients generation algorithm to create a transfer function based on the parameters passed in, using a mathematical recipe. This means the filter is capable of behaving as several kinds of filter:\n\n\nButterworth\n\n\nDesigned to have a completely flat frequency response in the accepted range. This means that it treats all signals in the accepted range exactly the same.(Unicorn Trading Company, n.d.) \n\n\nIt is prone to overshooting however. This means that the processed signal can temporarily exceed the amplitude of the raw signal if it changes quickly, this can be seen in the image below.(Butterworth S, 1930)\n\n\n\n\nCritically Damped\n\n\nA critically damped filter is designed to remove the overshooting effect seen in the Butterworth filter. The compromise however, is that a delay is introduced on the processed data when a rapid change in the raw data occurs. In the image below we can see that the overshoot is removed but the ascending and descending leg of the filter lag behind the raw data considerably. \n\n\n\n\nBessel\n\n\nThis filter interferes the least with the frequencies in the accepted frequency range, and will not overshoot. It is a compromise between the significant suppression of the critically damped filter and the more active Butterworth filter.\n\nThe number of passes can be varied from 1 to 3, allowing the filter to be cascaded. Cascading filters can intensify their behaviour. For example, cascading the Butterworth filter will significantly increase the amount of overshoot. Cascading the critically damped filter will not cause it to overshoot. It will maintain the critical damping property. \nOverall, this filter is considerably more complex, particularly for the coefficients generation section of the algorithm, although this can be run only once. It does however offer a considerable amount of flexibility. Note that when the filter is started, the output signal will briefly drop to 0. This is normal and is part of the filter\u2019s start-up routine. To avoid issues with data, start the filter before it is required to process data to ensure that it is ready. \n\n\nComplexity:\n\n\n\n\nCoefficient Calculation: O(1)\n\n\nFilter application: O(n) where number \nn\n = of passes on filter.\n\n\n\n\nMemory load: \n\n\n\n\nCoefficient Calculation:  O(1)\n\n\nFilter application: O(1) - Changing the number of passes does not change the memory usage of the filter.\n\n\n\n\nParameters\n\n\n\n\n\n\n\n\nName and Type\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nn:Double\n  Range: 1...3\n\n\nDefines the number of passes of the filter. Increasing will cause the filter to cascade.\n\n\n\n\n\n\np:Double\n  Range: 0.2...5\n\n\nPolynomial coefficient partially defining the transfer function of the filter. A lower p makes the filter more responsive, decreasing the smoothing effect of the filter, but also reduces lag in sudden changes. Decreasing below 1 will cause resonating amplification. If an order larger than 1 is used simultaneously it will occur increasing amounts indefinitely until overflow occurs.\n\n\n\n\n\n\ng:Double\n  0.2...5\n\n\nGain constant of the filter, forming part of the transfer function, defines the values that make the transfer function return 1 when passed 0. A larger G will reduce lag, but may lead to overshoot. A value of G below 1 for any value of P above 1 will result in a critically damped filter.\n\n\n\n\n\n\n\n\nSuggested Parameter Setup\n\n\n\n\n\n\n\n\nFilter Name\n\n\nn\n\n\np\n\n\ng\n\n\n\n\n\n\n\n\n\n\nButterworth\n\n\n1\n\n\n1.4\n\n\n1\n\n\n\n\n\n\nCritically Damped\n\n\n1\u20263\n\n\n2\n\n\n1\n\n\n\n\n\n\nBessel\n\n\n1\n\n\n3\n\n\n3\n\n\n\n\n\n\nLinkwitz-Riley*\n\n\n2\n\n\n1.4\n\n\n1\n\n\n\n\n\n\n\n\nThe mathematics and parameter set up for this filter are described \nHere\n.\n\n\nMore information on Linkwitz-Riley filter\n\n\nTesting\n\n\nTests for this filter can be found in the \nadvancedLowPassTests.swift\n file.", 
            "title": "Low Pass Filter"
        }, 
        {
            "location": "/Low-Pass-Filter/#introduction-usage-and-behaviour", 
            "text": "This filter is conceptually the opposite of the high pass filter. It allows low frequency signals to pass through, while removing and smoothing out the high frequency ones. This makes it useful for removing noise from a signal. This filter is generic, and uses a coefficients generation algorithm to create a transfer function based on the parameters passed in, using a mathematical recipe. This means the filter is capable of behaving as several kinds of filter:  Butterworth  Designed to have a completely flat frequency response in the accepted range. This means that it treats all signals in the accepted range exactly the same.(Unicorn Trading Company, n.d.)   It is prone to overshooting however. This means that the processed signal can temporarily exceed the amplitude of the raw signal if it changes quickly, this can be seen in the image below.(Butterworth S, 1930)   Critically Damped  A critically damped filter is designed to remove the overshooting effect seen in the Butterworth filter. The compromise however, is that a delay is introduced on the processed data when a rapid change in the raw data occurs. In the image below we can see that the overshoot is removed but the ascending and descending leg of the filter lag behind the raw data considerably.    Bessel  This filter interferes the least with the frequencies in the accepted frequency range, and will not overshoot. It is a compromise between the significant suppression of the critically damped filter and the more active Butterworth filter. \nThe number of passes can be varied from 1 to 3, allowing the filter to be cascaded. Cascading filters can intensify their behaviour. For example, cascading the Butterworth filter will significantly increase the amount of overshoot. Cascading the critically damped filter will not cause it to overshoot. It will maintain the critical damping property. \nOverall, this filter is considerably more complex, particularly for the coefficients generation section of the algorithm, although this can be run only once. It does however offer a considerable amount of flexibility. Note that when the filter is started, the output signal will briefly drop to 0. This is normal and is part of the filter\u2019s start-up routine. To avoid issues with data, start the filter before it is required to process data to ensure that it is ready.   Complexity:   Coefficient Calculation: O(1)  Filter application: O(n) where number  n  = of passes on filter.   Memory load:    Coefficient Calculation:  O(1)  Filter application: O(1) - Changing the number of passes does not change the memory usage of the filter.", 
            "title": "Introduction, Usage and Behaviour"
        }, 
        {
            "location": "/Low-Pass-Filter/#parameters", 
            "text": "Name and Type  Description      n:Double   Range: 1...3  Defines the number of passes of the filter. Increasing will cause the filter to cascade.    p:Double   Range: 0.2...5  Polynomial coefficient partially defining the transfer function of the filter. A lower p makes the filter more responsive, decreasing the smoothing effect of the filter, but also reduces lag in sudden changes. Decreasing below 1 will cause resonating amplification. If an order larger than 1 is used simultaneously it will occur increasing amounts indefinitely until overflow occurs.    g:Double   0.2...5  Gain constant of the filter, forming part of the transfer function, defines the values that make the transfer function return 1 when passed 0. A larger G will reduce lag, but may lead to overshoot. A value of G below 1 for any value of P above 1 will result in a critically damped filter.", 
            "title": "Parameters"
        }, 
        {
            "location": "/Low-Pass-Filter/#suggested-parameter-setup", 
            "text": "Filter Name  n  p  g      Butterworth  1  1.4  1    Critically Damped  1\u20263  2  1    Bessel  1  3  3    Linkwitz-Riley*  2  1.4  1     The mathematics and parameter set up for this filter are described  Here .  More information on Linkwitz-Riley filter", 
            "title": "Suggested Parameter Setup"
        }, 
        {
            "location": "/Low-Pass-Filter/#testing", 
            "text": "Tests for this filter can be found in the  advancedLowPassTests.swift  file.", 
            "title": "Testing"
        }, 
        {
            "location": "/High-Pass-Filter/", 
            "text": "Introduction, Usage and Behaviour\n\n\nThe high pass filter is the simplest of the filtering algorithms included in the library, but is extremely useful. The filter functions by allowing high frequency signals to pass, but removing low frequency ones. This makes it useful for isolating and removing bias in a signal such as gravity. It does not however remove high frequency noise that is often characteristic of MEMS sensors.\n\n\nComplexity:\n\n\n\n\nCoefficient Calculation:  O(1)\n\n\nFilter application: O(1)\n\n\n\n\nMemory load: \n\n\n\n\nCoefficient Calculation:  O(1)\n\n\nFilter application: O(1)\n\n\n\n\nThe complexity and memory requirements of this filter are constant and trivial. At any one time the algorithm keeps track of the previous raw and processed value.\n\n\nParameters\n\n\n\n\n\n\n\n\nName and Type\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nCutPoint:Double\n  Range: 0...10\n\n\nFrequency at which the signal is attenuated. The lower this value, the lower the frequency of a signal needs to be to be attenuated. This results in a less active filter that takes longer to return to zero after displacement.\n\n\n\n\n\n\nFreq:Double\n\n\nThe frequency of the sampling source. This is used in the coefficient calculation.\n\n\n\n\n\n\n\n\n\n\nIt can be seen that when a small cut-off frequency is used, the time taken for the filter to bring the signal back to 0. At very high values we can see that this is almost instantaneous. When working with this filter it is important to strike a balance between responsiveness and over activity cutting out useful data.\n\n\nTesting\n\n\nTests for this filter can be found in the \nhighPassTests.swift\n file.", 
            "title": "High Pass Filter"
        }, 
        {
            "location": "/High-Pass-Filter/#introduction-usage-and-behaviour", 
            "text": "The high pass filter is the simplest of the filtering algorithms included in the library, but is extremely useful. The filter functions by allowing high frequency signals to pass, but removing low frequency ones. This makes it useful for isolating and removing bias in a signal such as gravity. It does not however remove high frequency noise that is often characteristic of MEMS sensors.  Complexity:   Coefficient Calculation:  O(1)  Filter application: O(1)   Memory load:    Coefficient Calculation:  O(1)  Filter application: O(1)   The complexity and memory requirements of this filter are constant and trivial. At any one time the algorithm keeps track of the previous raw and processed value.", 
            "title": "Introduction, Usage and Behaviour"
        }, 
        {
            "location": "/High-Pass-Filter/#parameters", 
            "text": "Name and Type  Description      CutPoint:Double   Range: 0...10  Frequency at which the signal is attenuated. The lower this value, the lower the frequency of a signal needs to be to be attenuated. This results in a less active filter that takes longer to return to zero after displacement.    Freq:Double  The frequency of the sampling source. This is used in the coefficient calculation.      It can be seen that when a small cut-off frequency is used, the time taken for the filter to bring the signal back to 0. At very high values we can see that this is almost instantaneous. When working with this filter it is important to strike a balance between responsiveness and over activity cutting out useful data.", 
            "title": "Parameters"
        }, 
        {
            "location": "/High-Pass-Filter/#testing", 
            "text": "Tests for this filter can be found in the  highPassTests.swift  file.", 
            "title": "Testing"
        }, 
        {
            "location": "/Total-Variation-Denoising-Filter/", 
            "text": "Introduction, Usage and Behaviour\n\n\nThis is yet another style of filter that is better suited to batch processing of data. This means that if for example you are recording data and not using it in real time, this filter can be used to yield an extremely clean signal, by passing in all the data at once. For the purposes of the live demo, the data points are batched together in a buffer and processed in groups of size 10 to 1000. The larger the batch size, the longer the lag, but the more consistent the output data. \nThis filter is an implementation of the total variation denoising method proposed in \u201cLaurent Condat. A Direct Algorithm for 1D Total Variation Denoising. 2013.\u201d Broadly, the filter operates by creating a value that it tries to preserve for as long as possible, as it moves through the data. For as long as it can do this, the generated value is set as the output at that point. If it cannot preserve, it backtracks to a point where a new value can be generated, set it as the new point to preserve and continues. (Condat, 2013). More information on the detailed operation can be found in the paper mentioned above. The output of this filter is a flat value, with instant jumps to new values, similar in style to the output of the bounded average filter.\nThe filter only considers values looking forward from its current position in the dataset, meaning that memory usage is minimal. It also means however that the output is sensitive to the size of the input dataset. Therefore, the maximum allowable dataset size should be passed in. This filter can be combined with low pass filter to great effect. The clean output of the total variation filter is combined with the smoothing effect of the low pass algorithm to create a clean, smooth signal that responds quickly and decisively to change, making the combination ideal for applications such as games where specific movements are triggered by accelerometer events. \n\n\nComplexity:\n\n Filter application: O(n^2) where \nn\n = number of points in the input dataset.\nMemory load: \n\n Coefficient Calculation: O(n^2) where \nn\n = number of points in the input dataset.\n\n\nInformation on the complexity of this algorithm is provided in the paper discussed above. (Condat, 2013)\nWhen using this filter in the showcase app, the graph may appear to freeze. This is normal behaviour, and the graph will update with new values as they are batch processed. This effect can be reduced by selecting a smaller batch size. The live raw data can be viewed by tapping settings and then unchecking Single Raw \n Filtered Graph. The bottom graph will update in jumps as new processed data becomes available.\n\n\nParameters\n\n\n\n\n\n\n\n\nName and Type\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nlambda:Double\n  Range: 0.01...1\n\n\nDefines the sensitivity of the filter to changes in value. The larger the lambda value, the larger change in acceleration is required to trigger an update of the output value. It also causes instantaneous jumps to be larger when they occur. This should be tested to a value that is above the level of noise in your data but below the magnitude of changes that are considered meaningful.\n\n\n\n\n\n\nbufferSize:Double\n  Range: 1...n\n\n\nDefines the size of the batch to be processed at once. When using the filter for real-time applications this will define the delay. For efficiency and output data consistency, the largest acceptable value should be used.\n\n\n\n\n\n\n\n\n\n\nThe sample graphs above show some of the characteristic behaviour of the total variation denoising filter. The first displays clearly how the overall movement in the data is isolated by removing extreme peaks and troughs. It also shows the flat tops at the maxima and minima of the data, characteristic of this algorithm. The middle is included to clearly display the way in which the filter behaves with sudden changes. It can be seen that a single instantaneous jump was made from the old signal value to the new. The effect of selecting a smaller batch size can be seen in the last image. Compared to the first, the processed data more closely resembles the raw data, and the flat tops at maxima and minima are smaller and less clear. \n\n\nTesting\n\n\nTests for this filter can be found in the \ntotalVarTests.swift\n file", 
            "title": "Total Variation Denoising Filter"
        }, 
        {
            "location": "/Total-Variation-Denoising-Filter/#introduction-usage-and-behaviour", 
            "text": "This is yet another style of filter that is better suited to batch processing of data. This means that if for example you are recording data and not using it in real time, this filter can be used to yield an extremely clean signal, by passing in all the data at once. For the purposes of the live demo, the data points are batched together in a buffer and processed in groups of size 10 to 1000. The larger the batch size, the longer the lag, but the more consistent the output data. \nThis filter is an implementation of the total variation denoising method proposed in \u201cLaurent Condat. A Direct Algorithm for 1D Total Variation Denoising. 2013.\u201d Broadly, the filter operates by creating a value that it tries to preserve for as long as possible, as it moves through the data. For as long as it can do this, the generated value is set as the output at that point. If it cannot preserve, it backtracks to a point where a new value can be generated, set it as the new point to preserve and continues. (Condat, 2013). More information on the detailed operation can be found in the paper mentioned above. The output of this filter is a flat value, with instant jumps to new values, similar in style to the output of the bounded average filter.\nThe filter only considers values looking forward from its current position in the dataset, meaning that memory usage is minimal. It also means however that the output is sensitive to the size of the input dataset. Therefore, the maximum allowable dataset size should be passed in. This filter can be combined with low pass filter to great effect. The clean output of the total variation filter is combined with the smoothing effect of the low pass algorithm to create a clean, smooth signal that responds quickly and decisively to change, making the combination ideal for applications such as games where specific movements are triggered by accelerometer events.   Complexity:  Filter application: O(n^2) where  n  = number of points in the input dataset.\nMemory load:   Coefficient Calculation: O(n^2) where  n  = number of points in the input dataset.  Information on the complexity of this algorithm is provided in the paper discussed above. (Condat, 2013)\nWhen using this filter in the showcase app, the graph may appear to freeze. This is normal behaviour, and the graph will update with new values as they are batch processed. This effect can be reduced by selecting a smaller batch size. The live raw data can be viewed by tapping settings and then unchecking Single Raw   Filtered Graph. The bottom graph will update in jumps as new processed data becomes available.", 
            "title": "Introduction, Usage and Behaviour"
        }, 
        {
            "location": "/Total-Variation-Denoising-Filter/#parameters", 
            "text": "Name and Type  Description      lambda:Double   Range: 0.01...1  Defines the sensitivity of the filter to changes in value. The larger the lambda value, the larger change in acceleration is required to trigger an update of the output value. It also causes instantaneous jumps to be larger when they occur. This should be tested to a value that is above the level of noise in your data but below the magnitude of changes that are considered meaningful.    bufferSize:Double   Range: 1...n  Defines the size of the batch to be processed at once. When using the filter for real-time applications this will define the delay. For efficiency and output data consistency, the largest acceptable value should be used.      The sample graphs above show some of the characteristic behaviour of the total variation denoising filter. The first displays clearly how the overall movement in the data is isolated by removing extreme peaks and troughs. It also shows the flat tops at the maxima and minima of the data, characteristic of this algorithm. The middle is included to clearly display the way in which the filter behaves with sudden changes. It can be seen that a single instantaneous jump was made from the old signal value to the new. The effect of selecting a smaller batch size can be seen in the last image. Compared to the first, the processed data more closely resembles the raw data, and the flat tops at maxima and minima are smaller and less clear.", 
            "title": "Parameters"
        }, 
        {
            "location": "/Total-Variation-Denoising-Filter/#testing", 
            "text": "Tests for this filter can be found in the  totalVarTests.swift  file", 
            "title": "Testing"
        }, 
        {
            "location": "/_Sidebar/", 
            "text": "Introduction\n\n\nShowcase App\n\n\nHow to Use the Showcase App\n\n\nUsing an Apple Watch with the Showcase App\n\n\nSensor Data Flow Management Tools\n\n\nLibrary Organisation\n\n\nImplementing Apple Watch Sensor Communication\n\n\nUsing the Data Source Manager\n\n\nUsing the Filter Manager\n\n\nFilter Algorithm Implementation\n\n\nHow To Implement a Filter Algorithm\n\n\nFilter Protocol\n\n\nData Point Object\n\n\nAlgorithm Specifications\n\n\nHigh Pass Filter\n\n\nLow Pass Filter\n\n\nBounded Average Filter\n\n\nSavitzky-Golay Filter\n\n\nTotal Variation Denoising Filter", 
            "title": "Index"
        }, 
        {
            "location": "/_Sidebar/#introduction", 
            "text": "", 
            "title": "Introduction"
        }, 
        {
            "location": "/_Sidebar/#showcase-app", 
            "text": "How to Use the Showcase App  Using an Apple Watch with the Showcase App", 
            "title": "Showcase App"
        }, 
        {
            "location": "/_Sidebar/#sensor-data-flow-management-tools", 
            "text": "Library Organisation  Implementing Apple Watch Sensor Communication  Using the Data Source Manager  Using the Filter Manager", 
            "title": "Sensor Data Flow Management Tools"
        }, 
        {
            "location": "/_Sidebar/#filter-algorithm-implementation", 
            "text": "How To Implement a Filter Algorithm  Filter Protocol  Data Point Object", 
            "title": "Filter Algorithm Implementation"
        }, 
        {
            "location": "/_Sidebar/#algorithm-specifications", 
            "text": "High Pass Filter  Low Pass Filter  Bounded Average Filter  Savitzky-Golay Filter  Total Variation Denoising Filter", 
            "title": "Algorithm Specifications"
        }
    ]
}